{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91889126-297c-4770-b48e-764853f30de8",
   "metadata": {},
   "source": [
    "## Paso 3: Técnica de Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96dcecd4-05f8-400d-92e4-82db95f99c15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Columnas  \\\n",
      "14  (person_age, person_income, cb_person_cred_his...   \n",
      "11            (person_age, person_income, loan_grade)   \n",
      "3                                       (loan_grade,)   \n",
      "6                            (person_age, loan_grade)   \n",
      "9            (cb_person_cred_hist_length, loan_grade)   \n",
      "12  (person_age, cb_person_cred_hist_length, loan_...   \n",
      "0                                       (person_age,)   \n",
      "1                                    (person_income,)   \n",
      "2                       (cb_person_cred_hist_length,)   \n",
      "4                         (person_age, person_income)   \n",
      "5            (person_age, cb_person_cred_hist_length)   \n",
      "7         (person_income, cb_person_cred_hist_length)   \n",
      "8                         (person_income, loan_grade)   \n",
      "10  (person_age, person_income, cb_person_cred_his...   \n",
      "13  (person_income, cb_person_cred_hist_length, lo...   \n",
      "\n",
      "          Matriz de Confusión  Exactitud  Precisión  Sensibilidad  F1 Score  \\\n",
      "14  [[4877, 233], [941, 466]]   0.819856   0.666667      0.331201  0.442545   \n",
      "11  [[4869, 241], [946, 461]]   0.817861   0.656695      0.327647  0.437174   \n",
      "3   [[5027, 83], [1235, 172]]   0.797760   0.674510      0.122246  0.206980   \n",
      "6   [[5027, 83], [1235, 172]]   0.797760   0.674510      0.122246  0.206980   \n",
      "9   [[5027, 83], [1235, 172]]   0.797760   0.674510      0.122246  0.206980   \n",
      "12  [[5027, 83], [1235, 172]]   0.797760   0.674510      0.122246  0.206980   \n",
      "0      [[5110, 0], [1407, 0]]   0.784103   0.000000      0.000000  0.000000   \n",
      "1      [[5110, 0], [1407, 0]]   0.784103   0.000000      0.000000  0.000000   \n",
      "2      [[5110, 0], [1407, 0]]   0.784103   0.000000      0.000000  0.000000   \n",
      "4      [[5110, 0], [1407, 0]]   0.784103   0.000000      0.000000  0.000000   \n",
      "5      [[5110, 0], [1407, 0]]   0.784103   0.000000      0.000000  0.000000   \n",
      "7      [[5110, 0], [1407, 0]]   0.784103   0.000000      0.000000  0.000000   \n",
      "8      [[5110, 0], [1407, 0]]   0.784103   0.000000      0.000000  0.000000   \n",
      "10     [[5110, 0], [1407, 0]]   0.784103   0.000000      0.000000  0.000000   \n",
      "13     [[5110, 0], [1407, 0]]   0.784103   0.000000      0.000000  0.000000   \n",
      "\n",
      "    Tiempo de Entrenamiento  Tiempo de Prueba  \n",
      "14                 0.052357          0.016120  \n",
      "11                 0.046237          0.017129  \n",
      "3                  0.010520          0.017031  \n",
      "6                  0.029303          0.016526  \n",
      "9                  0.014036          0.015520  \n",
      "12                 0.030077          0.016113  \n",
      "0                  0.052246          0.016074  \n",
      "1                  0.018046          0.017122  \n",
      "2                  0.014041          0.015511  \n",
      "4                  0.020809          0.019537  \n",
      "5                  0.030151          0.019033  \n",
      "7                  0.015536          0.017033  \n",
      "8                  0.019096          0.017520  \n",
      "10                 0.017658          0.016097  \n",
      "13                 0.016556          0.016136  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Se cargan los datos en un DataFrame\n",
    "df_datos = pd.read_csv(\"datos/credit_risk_dataset.csv\")\n",
    "\n",
    "columnas_importantes = ['person_age', 'person_income', 'loan_status', 'cb_person_cred_hist_length', 'loan_grade']\n",
    "\n",
    "# Se crea una instancia de SimpleImputer con la estrategia de imputación como la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_datos[columnas_importantes] = imputer.fit_transform(df_datos[columnas_importantes])\n",
    "\n",
    "# Crear una instancia de OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Ajustar y transformar la columna 'loan_grade' usando OrdinalEncoder\n",
    "encoded_loan_grade = ordinal_encoder.fit_transform(df_datos[['loan_grade']])\n",
    "\n",
    "# Crear un DataFrame con la codificación ordinal de 'loan_grade'\n",
    "encoded_loan_grade = pd.DataFrame(encoded_loan_grade, columns=['loan_grade'])\n",
    "\n",
    "# Eliminar la columna original 'loan_grade' y concatenar la nueva codificación ordinal\n",
    "df_datos = pd.concat([df_datos.drop(columns=['loan_grade']), encoded_loan_grade], axis=1)\n",
    "\n",
    "# Se crea una lista de todas las columnas\n",
    "todas_columnas = ['person_age', 'person_income', 'cb_person_cred_hist_length', 'loan_grade']\n",
    "\n",
    "# DataFrame para almacenar resultados\n",
    "resultados = []\n",
    "\n",
    "# Se genera una única vez el conjunto de datos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_datos[todas_columnas], df_datos['loan_status'], test_size=0.2, random_state=100)\n",
    "\n",
    "# Se generan todas las combinaciones posibles de columnas\n",
    "for r in range(1, len(todas_columnas) + 1):\n",
    "    combinaciones_columnas = combinations(todas_columnas, r)\n",
    "    # Se itera sobre cada combinación de columnas\n",
    "    for cols in combinaciones_columnas:\n",
    "        start_time_training = time.time()\n",
    "        # Se crea y entrena el modelo de clasificación de Regresión Logística\n",
    "        clasificador_regresion_logistica = LogisticRegression()\n",
    "        modelo_clasificador_regresion_logistica = clasificador_regresion_logistica.fit(X_train[list(cols)], y_train)\n",
    "        end_time_training = time.time()\n",
    "\n",
    "        start_time_testing = time.time()\n",
    "        # Se predicen las salidas de datos de prueba\n",
    "        y_test_predicho = modelo_clasificador_regresion_logistica.predict(X_test[list(cols)])\n",
    "\n",
    "        # Se calculan las métricas para evaluar el modelo de clasificación\n",
    "        mc = confusion_matrix(y_test, y_test_predicho)\n",
    "        e = accuracy_score(y_test, y_test_predicho)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            p = precision_score(y_test, y_test_predicho)\n",
    "\n",
    "        s = recall_score(y_test, y_test_predicho)\n",
    "        f1 = f1_score(y_test, y_test_predicho)\n",
    "        end_time_testing = time.time()\n",
    "\n",
    "        # Se calculan los tiempos de ejecución\n",
    "        training_time = end_time_training - start_time_training\n",
    "        testing_time = end_time_testing - start_time_testing\n",
    "\n",
    "        # Se almacenan los resultados en el DataFrame de resultados\n",
    "        resultados.append([cols, mc, e, p, s, f1, training_time, testing_time])\n",
    "\n",
    "# Se crea el DataFrame final\n",
    "df_resultados = pd.DataFrame(resultados, columns=['Columnas', 'Matriz de Confusión', 'Exactitud', 'Precisión', 'Sensibilidad', 'F1 Score', 'Tiempo de Entrenamiento', 'Tiempo de Prueba'])\n",
    "\n",
    "# Se ordena el DataFrame por Exactitud\n",
    "df_resultados = df_resultados.sort_values(by='Exactitud', ascending=False)\n",
    "\n",
    "# Se muestra el DataFrame final\n",
    "print(df_resultados)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
